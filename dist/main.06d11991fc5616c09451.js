"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[792],{112:(e,s,a)=>{var i=a(848),n=a(540),r=a(338),t=a(526);function l(){return(0,i.jsxs)("div",{children:[(0,i.jsx)("nav",{className:"navbar",role:"navigation","aria-label":"main navigation",children:(0,i.jsx)("div",{className:"navbar-brand",children:(0,i.jsxs)("a",{role:"button",className:"navbar-burger","aria-label":"menu","aria-expanded":"false",children:[(0,i.jsx)("span",{"aria-hidden":"true"}),(0,i.jsx)("span",{"aria-hidden":"true"}),(0,i.jsx)("span",{"aria-hidden":"true"})]})})}),(0,i.jsx)("section",{className:"hero",children:(0,i.jsx)("div",{className:"hero-body",children:(0,i.jsx)("div",{className:"container is-max-desktop",children:(0,i.jsx)("div",{className:"columns is-centered",children:(0,i.jsxs)("div",{className:"column has-text-centered",children:[(0,i.jsx)("h1",{className:"title is-1 publication-title",children:"Eyes Tell the Truth: GazeVal Highlights Shortcomings of Generative AI in Medical Imaging"}),(0,i.jsxs)("div",{className:"is-size-5 publication-authors",children:[(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"David Wong*"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Bin Wang*"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Gorkem Durak"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Marouane Tliba"}),(0,i.jsx)("sup",{children:"2"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Akshay Chaudhari"}),(0,i.jsx)("sup",{children:"3"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Aladine Chetouani"}),(0,i.jsx)("sup",{children:"4"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Ahmet Enis Cetin"}),(0,i.jsx)("sup",{children:"2"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Cagdas Topel"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Nicolo Gennaro"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Camila Lopes Vendrami"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Tugce Agirlar Trabzonlu"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Amir Ali Rahsepar"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Laetitia Perronne"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Matthew Antalek"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Onural Ozturk"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Gokcan Okur"}),(0,i.jsx)("sup",{children:"5"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Andrew C. Gordon"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Ayis Pyrros"}),(0,i.jsx)("sup",{children:"6"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Frank H. Miller"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Amir Borhani"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Hatice Savas"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Eric Hart"}),(0,i.jsx)("sup",{children:"1"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Drew Torigian"}),(0,i.jsx)("sup",{children:"7"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Jayaram K. Udupa"}),(0,i.jsx)("sup",{children:"7"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Elizabeth Krupinski"}),(0,i.jsx)("sup",{children:"8"}),","]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("a",{href:"#",children:"Ulas Bagci"}),(0,i.jsx)("sup",{children:"1"})]})]}),(0,i.jsxs)("div",{className:"is-size-5 publication-authors",children:[(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("sup",{children:"1"}),"Northwestern University,"]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("sup",{children:"2"}),"University of Illinois at Chicago,"]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("sup",{children:"3"}),"Stanford University,"]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("sup",{children:"4"}),"Université Sorbonne Paris Nord,"]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("sup",{children:"5"}),"Loyola University Chicago,"]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("sup",{children:"6"}),"DuPage Medical Group,"]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("sup",{children:"7"}),"University of Pennsylvania,"]}),(0,i.jsxs)("span",{className:"author-block",children:[(0,i.jsx)("sup",{children:"8"}),"Emory University"]})]}),(0,i.jsx)("div",{className:"is-size-6",children:(0,i.jsx)("em",{children:"* Equal contribution."})}),(0,i.jsx)("div",{className:"column has-text-centered",children:(0,i.jsx)("div",{className:"publication-links",children:(0,i.jsx)("span",{className:"link-block",children:(0,i.jsxs)("a",{href:"https://arxiv.org/pdf/2503.20967",className:"external-link button is-normal is-rounded is-dark",target:"_blank",rel:"noopener noreferrer",children:[(0,i.jsx)("span",{className:"icon",children:(0,i.jsx)("i",{className:"fas fa-file-pdf"})}),(0,i.jsx)("span",{children:"Paper"})]})})})})]})})})})}),(0,i.jsx)("section",{className:"hero teaser",children:(0,i.jsx)("div",{className:"container is-max-desktop",children:(0,i.jsxs)("div",{className:"hero-body",children:[(0,i.jsx)("div",{className:"image-container",children:(0,i.jsx)("img",{className:"img-responsive",src:"./assets/gazeval/framework.png",alt:"Teaser Image"})}),(0,i.jsx)("h2",{className:"subtitle has-text-centered",children:"Overview of the proposed GazeVal framework, which introduces two tasks with corresponding evaluation metrics to quantitatively assess the quality of synthetic Chest X-ray images with expert knowledge."})]})})}),(0,i.jsx)("section",{className:"section",children:(0,i.jsx)("div",{className:"container is-max-desktop",children:(0,i.jsx)("div",{className:"columns is-centered has-text-centered",children:(0,i.jsxs)("div",{className:"column is-four-fifths",children:[(0,i.jsx)("h2",{className:"title is-3",children:"Abstract"}),(0,i.jsx)("div",{className:"content has-text-justified",children:(0,i.jsx)("p",{children:"The demand for high-quality synthetic data for model training and augmentation has never been greater in medical imaging. However, current evaluations predominantly rely on computational metrics that fail to align with human expert recognition. This leads to synthetic images that may appear realistic numerically but lack clinical authenticity, posing significant challenges in ensuring the reliability and effectiveness of AI-driven medical tools. To address this gap, we introduce GazeVal, a practical framework that synergizes expert eye-tracking data with direct radiological evaluations to assess the quality of synthetic medical images. GazeVal leverages gaze patterns of radiologists as they provide a deeper understanding of how experts perceive and interact with synthetic data in different tasks (i.e., diagnostic or Turing tests). Experiments with sixteen radiologists revealed that 96.6% of the generated images (by the most recent state-of-the-art AI algorithm) were identified as fake, demonstrating the limitations of generative AI in producing clinically accurate images."})})]})})})}),(0,i.jsx)("section",{className:"section",children:(0,i.jsx)("div",{className:"container is-max-desktop",children:(0,i.jsx)("div",{className:"columns is-centered ",children:(0,i.jsxs)("div",{className:"column is-full-width",children:[(0,i.jsx)("h2",{className:"title is-3 has-text-centered",style:{marginTop:-30},children:"Methods"}),(0,i.jsx)("br",{}),(0,i.jsx)("div",{className:"subtitle has-text-justified",children:(0,i.jsx)("p",{children:"Given a real chest X-ray image and its associated report, a synthetic chest X-ray image is generated based on the report by an LDM-based generative model, RoentGen. The synthetic images are then placed in a dataset with real images and reviewed by radiologists under two task settings. First, radiologists are asked to provide a diagnosis without knowing that synthetic images are included. Second, they are asked to determine whether each image is real or generated. At the same time, we use eye tracking to record their eye gaze during the tasks. Using the gaze data and their task answers, we can compare synthetic and real X-rays across various metrics to evaluate the quality of the synthetic images."})}),(0,i.jsx)("div",{className:"image-container",children:(0,i.jsx)("img",{className:"img-responsive",src:"./assets/gazeval/setup.png",alt:"one click"})}),(0,i.jsx)("br",{}),(0,i.jsx)("div",{className:"subtitle has-text-justified",children:(0,i.jsx)("p",{children:"Left: Eye tracking setup. The radiologist is viewing the image on the monitor with the eye tracker in between them. Middle: EyeLink 1000 Plus eye-tracker view with calibration software. Right: Eye-tracker and example attention map."})})]})})})}),(0,i.jsx)("section",{className:"section",children:(0,i.jsx)("div",{className:"container is-max-desktop",children:(0,i.jsx)("div",{className:"columns is-centered ",children:(0,i.jsxs)("div",{className:"column is-full-width",children:[(0,i.jsx)("h2",{className:"title is-3 has-text-centered",style:{marginTop:-30},children:"Results"}),(0,i.jsx)("br",{}),(0,i.jsxs)("div",{className:"subtitle has-text-justified",children:[(0,i.jsx)("p",{children:"(1) This means the diagnostic agreement for real and synthetic images are similar."}),(0,i.jsx)("p",{children:"(2) Radiologists can accurately distinguish between real and synthetic images, which means the current state-of-the-art generative model are unable to generate highly realistic radiological images yet."})]}),(0,i.jsx)("div",{className:"image-container",children:(0,i.jsx)("img",{className:"img-responsive",src:"./assets/gazeval/Box_Whisker2.png",alt:"one click"})}),(0,i.jsx)("br",{}),(0,i.jsx)("div",{className:"subtitle has-text-justified",children:(0,i.jsx)("p",{children:"(3) Differing viewing patterns of real and synthetic X-rays are present and increase with prolonged visual processing."})}),(0,i.jsx)("div",{className:"image-container",children:(0,i.jsx)("img",{className:"img-responsive",src:"./assets/gazeval/table.png",alt:"one click"})})]})})})}),(0,i.jsx)("section",{className:"section",children:(0,i.jsx)("div",{className:"container is-max-desktop",children:(0,i.jsx)("div",{className:"columns is-centered ",children:(0,i.jsxs)("div",{className:"column is-full-width",children:[(0,i.jsx)("div",{className:"subtitle has-text-justified",children:(0,i.jsx)("p",{children:"(4) Using both Fixation-Based and Scanpath-Based Congruency, as well as shared attention calculations, we quantitatively determine that visual attention is task-guided."})}),(0,i.jsx)("div",{className:"image-container",children:(0,i.jsx)("img",{className:"img-responsive",src:"./assets/gazeval/Table2.png",style:{maxWidth:"100%",height:"auto"},alt:"one click"})}),(0,i.jsx)("br",{}),(0,i.jsx)("div",{className:"image-container",children:(0,i.jsx)("img",{className:"img-responsive",src:"./assets/gazeval/IoUFigure3.png",style:{maxWidth:"100%",height:"auto"},alt:"one click"})}),(0,i.jsx)("br",{}),(0,i.jsx)("div",{className:"subtitle has-text-justified",children:(0,i.jsx)("p",{children:"(5) Generative models struggle more to generate realistic X-rays when containing pathologies."})}),(0,i.jsx)("div",{className:"image-container",children:(0,i.jsx)("img",{className:"img-responsive",src:"./assets/gazeval/pathology.png",alt:"one click"})})]})})})}),(0,i.jsx)("section",{className:"section",id:"BibTeX",children:(0,i.jsxs)("div",{className:"container is-max-desktop content",children:[(0,i.jsx)("h2",{className:"title",children:"BibTeX"}),(0,i.jsx)("pre",{className:"bibtex",children:(0,i.jsx)("code",{children:"@misc{wong2025eyestelltruthgazeval,\n  title={Eyes Tell the Truth: GazeVal Highlights Shortcomings of Generative AI in Medical Imaging}, \n  author={David Wong and Bin Wang and Gorkem Durak and Marouane Tliba and Akshay Chaudhari and Aladine Chetouani and Ahmet Enis Cetin and Cagdas Topel and Nicolo Gennaro and Camila Lopes Vendrami and Tugce Agirlar Trabzonlu and Amir Ali Rahsepar and Laetitia Perronne and Matthew Antalek and Onural Ozturk and Gokcan Okur and Andrew C. Gordon and Ayis Pyrros and Frank H. Miller and Amir Borhani and Hatice Savas and Eric Hart and Drew Torigian and Jayaram K. Udupa and Elizabeth Krupinski and Ulas Bagci},\n  year={2025},\n  eprint={2503.20967},\n  archivePrefix={arXiv},\n  primaryClass={cs.CV},\n  url={https://arxiv.org/abs/2503.20967}, \n}"})})]})})]})}function c(e){var s=e.images,a=e.intervalMs,r=void 0===a?3e3:a,t=e.maxHeight,l=void 0===t?400:t,c=(0,n.useState)(0),o=c[0],h=c[1],d=(0,n.useRef)(null),m=(0,n.useRef)(null);function u(){x(),d.current=window.setInterval(function(){h(function(e){return(e+1)%s.length})},r)}function x(){null!==d.current&&(clearInterval(d.current),d.current=null)}function g(){h(function(e){return(e-1+s.length)%s.length}),u()}function p(){h(function(e){return(e+1)%s.length}),u()}return(0,n.useEffect)(function(){if(s&&0!==s.length)return u(),x},[s]),(0,i.jsxs)("div",{className:"carousel",id:"headshotCarousel",ref:m,role:"region","aria-label":"Photo carousel",tabIndex:0,onKeyDown:function(e){"ArrowLeft"===e.key?g():"ArrowRight"===e.key&&p()},onMouseEnter:x,onMouseLeave:u,style:{position:"relative",height:"number"==typeof l?"".concat(l,"px"):l},children:[(0,i.jsx)("div",{className:"carousel-track",style:{width:"100%",textAlign:"center"},children:s.map(function(e,s){return(0,i.jsx)("img",{src:e,alt:"Photo ".concat(s+1),className:"carousel-image".concat(s===o?" active":""),style:{display:s===o?"inline-block":"none",maxHeight:l,maxWidth:"100%",borderRadius:"8px",margin:"0 auto",padding:"8px",boxSizing:"border-box"}},e)})}),(0,i.jsx)("button",{className:"carousel-control prev",onClick:g,"aria-label":"Previous photo",style:{position:"absolute",top:"50%",left:"16px",transform:"translateY(-50%)",border:"none",background:"rgba(0,0,0,0.5)",color:"white",padding:"8px",borderRadius:"50%",cursor:"pointer"},children:"❮"}),(0,i.jsx)("button",{className:"carousel-control next",onClick:p,"aria-label":"Next photo",style:{position:"absolute",top:"50%",right:"16px",transform:"translateY(-50%)",border:"none",background:"rgba(0,0,0,0.5)",color:"white",padding:"8px",borderRadius:"50%",cursor:"pointer"},children:"❯"})]})}function o(e){var s=e.title,a=e.items;return a&&0!==a.length?(0,i.jsxs)("section",{className:"publications",children:[(0,i.jsx)("h2",{className:"publications-title",children:s}),(0,i.jsx)("div",{className:"publications-list",children:a.map(function(e,s){var a;return(0,i.jsxs)("article",{className:"publication",children:[e.image&&(0,i.jsx)("div",{className:"publication-image",children:(0,i.jsx)("img",{src:e.image,alt:e.title})}),(0,i.jsxs)("div",{className:"publication-body",children:[(0,i.jsxs)("div",{className:"publication-meta",children:[(0,i.jsx)("div",{className:"publication-title",children:e.title}),e.authors&&(0,i.jsx)("div",{className:"publication-authors",children:e.authors}),e.venue&&(0,i.jsxs)("div",{className:"publication-venue",children:[e.venue," ",e.year?", ".concat(e.year):null]})]}),e.links&&(0,i.jsx)("div",{className:"publication-links",children:e.links.map(function(e,s){return e.href.startsWith("/")?(0,i.jsx)(t.N_,{to:e.href,className:"pub-link",children:e.label},s):(0,i.jsx)("a",{href:e.href,target:"_blank",rel:"noopener noreferrer",className:"pub-link",children:e.label},s)})})]})]},null!==(a=e.id)&&void 0!==a?a:s)})})]}):null}function h(){return(0,i.jsxs)("div",{style:{marginTop:25},children:[(0,i.jsxs)("div",{style:{display:"flex",gap:20},children:[(0,i.jsx)("div",{style:{flex:1},children:(0,i.jsxs)("div",{style:{fontFamily:"Verdana, sans-serif"},children:[(0,i.jsx)("b",{style:{fontSize:"2.5em",display:"block"},children:"David Wong"}),(0,i.jsx)("br",{}),(0,i.jsx)("span",{style:{fontSize:"1.5em"},children:"Northwestern University"}),(0,i.jsx)("br",{}),(0,i.jsx)("span",{style:{fontSize:"1.1em"},children:"Email: david.wong@u.northwestern.edu"}),(0,i.jsx)("br",{}),(0,i.jsxs)("div",{style:{fontSize:"1.1em",marginTop:10},children:[(0,i.jsx)("a",{href:"https://scholar.google.com/citations?user=PFAy4YkAAAAJ&hl=en",target:"_blank",rel:"noopener noreferrer",children:"Google Scholar"})," /",(0,i.jsx)("a",{href:"https://github.com/dc-wong",target:"_blank",rel:"noopener noreferrer",children:" Github"})," /",(0,i.jsx)("a",{href:"https://www.linkedin.com/in/david-c-w-nu2027/",target:"_blank",rel:"noopener noreferrer",children:" LinkedIn"})," /",(0,i.jsx)("a",{href:"./assets/docs/David_Wong_Resume.pdf",target:"_blank",rel:"noopener noreferrer",children:" Resume"})]})]})}),(0,i.jsx)("div",{style:{width:"35%",textAlign:"center"},children:(0,i.jsx)(c,{images:["./assets/self/img_1.jpg","./assets/self/img_2.jpg","./assets/self/img_3.jpeg","./assets/self/img_4.jpg","./assets/self/img_5.jpg"]})})]}),(0,i.jsx)("h2",{children:"About Me"}),(0,i.jsxs)("p",{children:["I am currently a third-year undergraduate student at ",(0,i.jsx)("a",{href:"https://www.northwestern.edu/",target:"_blank",children:"Northwestern University"})," studying biomedical medicacl engineering and computer science. I am currently working in ",(0,i.jsx)("a",{href:"https://www.regeneron.com/",target:"_blank",children:"Regeneron Pharmaceuticals"})," as a Data Engineering Co-op under ",(0,i.jsx)("a",{href:"https://www.linkedin.com/in/matthew-conway-7a4a5714/",target:"_blank",children:"Matthew Conway"}),". I conduct research in the ",(0,i.jsx)("a",{href:"https://bagcilab.com/",target:"_blank",children:"Machine and Hybrid Intelligence Lab"})," under ",(0,i.jsx)("a",{href:"https://scholar.google.com/citations?user=9LUdPM4AAAAJ&hl=en",target:"_blank",children:"Proffessor Ulas Bagci"})," as a Research Intern."]}),(0,i.jsx)(o,{title:"Publications",items:[{id:1,title:"Shifts in Doctors’ Eye Movements Between Real and AI-Generated Medical Images",authors:"David Wong*, Bin Wang*, Gorkem Durak, Marouane Tliba, et al.",venue:"ETRA",year:2025,links:[{label:"Paper",href:"https://arxiv.org/pdf/2504.15007"}],image:"./assets/projects/etralogo.png"},{id:2,title:"Eyes Tell the Truth: GazeVal Highlights Shortcomings of Generative AI in Medical Imaging",authors:"David Wong*, Bin Wang*, Gorkem Durak, Marouane Tliba, et al.",venue:"CVPRW [Oral]",year:2025,links:[{label:"Paper",href:"https://arxiv.org/pdf/2503.20967"},{label:"Project Page",href:"./gazeval"}],image:"./assets/projects/gazevallogo.png"}]}),(0,i.jsx)(o,{title:"Projects",items:[{id:1,title:"HALŌ",authors:"As a part of the Sanofi Design Innovation Challenge, we designed a large-volume, on-body delivery system to deliver medicine subcutaneously as an alternative to IV infusions which improves the mobility of patients and allows for at-home treatment administration. The design and development of this system is built upon market analysis and patient feedback while avoiding patent infringement. This description is limited as the competition is still in progress.",venue:"",year:2025,links:[{label:"Competition Page",href:"https://sanofi-challenge.web.app/"}],image:"./assets/projects/sanofi_logo.jpeg"},{id:2,title:"MILO: Voice-Controlled Robotic Arm",authors:"A robotic arm that responds to a user's voice commands to assist paraplegic patients & patients with limited upper limb strength to do daily tasks, such as connect with family via video calling & drink water. My primary contribution is voice recognition & response system by building a microphone that is able to hear the user in noisy environments, optimizing the system for lower costs and a smaller size while maintaining high audio quality, and integrating the system with Arduino's speech recognition. This project made it to RESNA Student Design Challenge Finalist 2024 and recceived an honorable mention from the TOM Global Innovation Challenge 2025.",venue:"",year:2025,links:[{label:"Project Page",href:"https://numedicalmakers.org/project1.html"}],image:"./assets/projects/milo_arm.png"}]})]})}r.createRoot(document.getElementById("root")).render((0,i.jsx)(t.Kd,{children:(0,i.jsx)(function(){return(0,i.jsx)("div",{children:(0,i.jsxs)(t.BV,{children:[(0,i.jsx)(t.qh,{path:"/",element:(0,i.jsx)(h,{})}),(0,i.jsx)(t.qh,{path:"/gazeval",element:(0,i.jsx)(l,{})})]})})},{})}))}},e=>{e.O(0,[900],()=>e(e.s=112)),e.O()}]);
//# sourceMappingURL=main.06d11991fc5616c09451.js.map